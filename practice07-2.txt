1.) For each of the following, denote which kind of cache miss is most likely given the described situation (compulsory, capacity, or conflict). Describe or otherwise justify your response, and give any assumptions you think might be necessary:
a.) A new program begins execution and initializes a large matrix.
b.) A data analytics program is processing a large dataset it holds in memory with irregular memory access patterns.
c.) A matrix-based computation program is repeatedly accessing the elements of a given column for a matrix. The matrix is stored row-wise as one long 1D array. The length of each row is equal to the number of sets in the cache. Assume we have a direct-mapped cache.


2.) You are given a three-way set associative cache with one-word blocks and a total size of 24 words. Assume we don't use any offset bits and addresses are accessed per-word. Using the sequence of references given below, show the cache access results if an LRU replacement algorithm is used. Assume the cache is initially empty. For each reference, identify the tag bits, index bits and if it is a hit or a miss. You can write each numeric value as a decimal (i.e., base 10) value.

3, 7, 15, 23, 3, 231, 232, 7, 11, 240

| Address | Tag | Index | Hit/Miss |
|---------|-----|-------|----------|


3.)
You are given a direct-mapped cache with 16-word blocks and a total size of 4096 words. Assume we have 2 byte offset bits.

How many bits are required for the tag bits?
How many bits are required for the index bits?
How many bits are required for the block offset bits?


4.) Assume you are given a cache with the following design constraints. The
cache size is 8,192 blocks in total where each block size is 8 words and the
address is 64 bits (not 32 bits!). How many BITS (not bytes) are used to
store the tag for the following 4 cache designs.

a.) Direct mapped.
b.) 2-way set associative.
c.) 4-way set associative.
d.) Fully associative.


5.) We know fully associate caches can minimize the number of incurred misses for many access patterns. Why are they not used in practice?


Solutions:

1.)
a.) Any miss would likely be *compulsory*. These are necessary misses that result from the first access by a program to a memory address. Initializing a chunk of memory would fall into this category.
b.) We have a large set of possible memory addresses and are assuming mostly random accesses. These misses would probably best fall under *capacity* misses. Although, it would probably be necessary to have the size of cache equal to the size of the dataset for these misses to be mitigated.
c.) Given the information we have, we can assume accesses to each column value in the matrix would be offset by an amount exactly equal to the size of our cache. Assuming that address->cache set is mapped as we did in the homework, each column address would map to the same set in our cache, giving us *conflict* misses.t


2.)
three-way set associative cache with one-word blocks and a total size of 24 words ==> three words per cache set ==> 8 cache sets

address = given value
tag = floor(address / #sets)
index = address % #sets
#sets = 8

addresses: 3, 7, 15, 23, 3, 231, 232, 7, 11, 240

| Address | Tag | Index | Hit/Miss |
|---------|-----|-------|----------|
|    3    |  0  |   3   |   miss   |
|    7    |  0  |   7   |   miss   |
|   15    |  1  |   7   |   miss   |
|   23    |  2  |   7   |   miss   |
|    3    |  0  |   3   |    hit   |
|  231    | 28  |   7   |   miss   |
|  232    | 29  |   0   |   miss   |
|    7    |  0  |   7   |   miss   |
|   11    |  1  |   3   |   miss   |
|  240    | 30  |   0   |   miss   |


3.) see slide 39 in Chapter-5 slides
Tag: 18 bits
Index: 8 bits
BOB: 4 bits


4.)
Block size is fixed, meaning that as we increase associativity, the number of cache sets decreases. 

8192 blocks in total where each block size is 8 words 

Each block has 8 words => BOB is 3 bits
Index size = 8192 / 8 / associativity
Assuming 2 bits for byte offset bits (assuming 0 is also fine)


| Associativity         | Index Size | Index Bits | BOB | Tag |
|-----------------------|------------|------------|-----|-----|
| Direct mapped         |    1024    |      10    |  3  |  49 |
| 2-way set associative |     512    |       9    |  3  |  50 |
| 4-way set associative |     256    |       8    |  3  |  51 |
| Fully associative     |       0    |       0    |  3  |  59 |


5.)
The number of checks for a given address you'll need to do is a function of the associativity. With full associativity, you'll need to check every single cache block for a given address. This is wildly inefficient. In addition, miss rate does not decrease linearly with an increasing associativity. There exist diminishing returns that make increases in associativity have little extra benefit in practice.